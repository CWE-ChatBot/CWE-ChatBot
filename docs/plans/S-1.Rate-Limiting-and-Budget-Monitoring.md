# S-1 Execution Plan (Edge Rate Limiting & Budget Monitoring)

**Owner:** Platform / SecOps
**Envs:** dev → staging → prod
**Related:** S-2 (LLM I/O guardrails), S-9 (Cloud Production Security)

---

## Objectives

1. Enforce **edge** rate limits (per-IP and per-user) using **Cloud Armor** on the HTTPS LB fronting Cloud Run.
2. Create **budget alerts** (daily + monthly) via the **Billing Budgets API** (REST) + **Cloud Monitoring** email channel.
3. Stand up **observability** (log-based metric + alert) for 429/rate-limit blocks.
4. Provide **black-box tests** that prove 200→429 behavior.

---

## Milestones & Timeline

* **M1 – Design sign-off (½ day)**
  Finalize limits per env, identity header (`X-User-Id`) source (IAP/API gateway/JWT).
* **M2 – Edge policies (1 day)**
  Create Cloud Armor policy + attach to LB (dev → staging).
* **M3 – Budgets & alerting (½ day)**
  Create Monitoring email channel; set daily/monthly budgets (REST).
* **M4 – Tests & runbook (1 day)**
  Black-box pytest + bash load test; runbook for tuning/triage.
* **M5 – Prod rollout (½ day)**
  Change window; validate, monitor, handoff.

---

## Configuration (uniform across all environments)

* **Per-IP limit:** **60 requests/minute**
* **Per-user limit:** **60 requests/minute** (keyed by `X-User-Id`)
* **Interval window:** **60 seconds**
* **Ban duration:** **300 seconds** (5 minutes)
* **Identity key:** `X-User-Id` (stable, verified ID derived from IAP/API gateway/JWT claim like `sub` or a hashed email).
* **Fallback:** If `X-User-Id` is absent, the per-IP rule still applies.
* **Observability & incident flow:** Shared with S-2/S-9.

> These values are **identical in dev, staging, and prod**. The scripts still accept env vars for exceptional ops (e.g., temporary tuning during an incident), but the baseline policy is the same everywhere.

### Pin the values in your scripts/CI (optional but recommended)

If you want to prevent accidental drift, set the same defaults in a shared ops env file (or your CI vars):

```bash
# scripts/.s1_uniform_limits.env
export RPM_PER_USER=60
export RPM_PER_IP=60
export INTERVAL_SEC=60
export BAN_COUNT_MULTIPLIER=2
export BAN_DURATION_SEC=300
export USER_HEADER=X-User-Id
```

Run the setup with pinned values:

```bash
source scripts/.s1_uniform_limits.env
PROJECT_ID=cwechatbot REGION=europe-west1 ./scripts/setup_rate_limits.sh
./scripts/setup_rate_limit_observability.sh
BILLING_ACCOUNT=000000-000000-000000 ./scripts/setup_budgets.sh
```

### Tests (no env-specific tweaks)

Use the same thresholds when proving 200 → 429:

```bash
STAGING_URL="https://staging.example.com/healthz" \
TEST_USER_ID="itest-user-1" \
TEST_RATE_LIMIT=10 \
pytest -q tests/integration/test_rate_limit.py

# or bash quick check
COUNT=15 USER_ID="itest-user-1" ./scripts/hit_until_429.sh https://staging.example.com/healthz
```

---



## Edge Setup (gcloud)

Create a Cloud Armor policy with **per-user** and **per-IP** rate limits.

**File:** `scripts/setup_rate_limits.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail

# ====== CONFIG ======
PROJECT_ID="${PROJECT_ID:-cwechatbot}"
REGION="${REGION:-europe-west1}"
POLICY="${POLICY:-edge-rate-limits}"
RPM_PER_USER="${RPM_PER_USER:-60}"
RPM_PER_IP="${RPM_PER_IP:-60}"
INTERVAL_SEC="${INTERVAL_SEC:-60}"
BAN_COUNT_MULTIPLIER="${BAN_COUNT_MULTIPLIER:-2}"  # e.g., 120 if rpm=60
BAN_DURATION_SEC="${BAN_DURATION_SEC:-300}"       # 5 minutes
USER_HEADER="${USER_HEADER:-X-User-Id}"
# ====================

gcloud config set project "${PROJECT_ID}"

# Create policy (idempotent-ish; ignore error if exists)
gcloud compute security-policies create "${POLICY}" \
  --description="Per-user (${USER_HEADER}) and per-IP rate limits" || true

# Per-user rule keyed by header
gcloud compute security-policies rules create 1000 \
  --security-policy="${POLICY}" \
  --action=rate-based-ban \
  --src-ip-ranges="*" \
  --expression="request.headers['${USER_HEADER}'] != null" \
  --rate-limit-threshold-count="${RPM_PER_USER}" \
  --rate-limit-threshold-interval-sec="${INTERVAL_SEC}" \
  --conform-action=deny-429 \
  --exceed-action=deny-429 \
  --ban-threshold-count="$((RPM_PER_USER * BAN_COUNT_MULTIPLIER))" \
  --ban-threshold-interval-sec="${INTERVAL_SEC}" \
  --ban-duration-sec="${BAN_DURATION_SEC}" \
  --enforce-on-key=HTTP_HEADER \
  --enforce-on-key-name="${USER_HEADER}" || true

# Per-IP default rule
gcloud compute security-policies rules create 1100 \
  --security-policy="${POLICY}" \
  --action=rate-based-ban \
  --src-ip-ranges="*" \
  --rate-limit-threshold-count="${RPM_PER_IP}" \
  --rate-limit-threshold-interval-sec="${INTERVAL_SEC}" \
  --conform-action=deny-429 \
  --exceed-action=deny-429 \
  --ban-threshold-count="$((RPM_PER_IP * BAN_COUNT_MULTIPLIER))" \
  --ban-threshold-interval-sec="${INTERVAL_SEC}" \
  --ban-duration-sec="${BAN_DURATION_SEC}" \
  --enforce-on-key=IP || true

echo "Cloud Armor policy created/updated: ${POLICY}"
echo "Next: attach ${POLICY} to the HTTPS LB backend service for your Cloud Run app."
```

> **Attach policy**: in your LB’s **Backend service**, set `security_policy` to `${POLICY}` (you can do this in console or with `gcloud compute backend-services update ... --security-policy=${POLICY}`).

---

## Observability Setup (gcloud)

Create a **log-based metric** for rate-limit blocks and an **alert** to your security email.

**File:** `scripts/setup_rate_limit_observability.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail

PROJECT_ID="${PROJECT_ID:-cwechatbot}"
ALERT_EMAIL="${ALERT_EMAIL:-security@example.com}"

gcloud config set project "${PROJECT_ID}"

# 1) Logging metric: count Cloud Armor 429 decisions
gcloud logging metrics create rate_limit_blocks \
  --description="Edge 429s from Cloud Armor / gateway" \
  --log-filter='severity>=ERROR AND (textPayload:"DENY_429" OR jsonPayload.enforcedAction="DENY_429")' || true

# 2) Notification channel (email)
cat > /tmp/email-channel.json <<JSON
{
  "type": "email",
  "displayName": "Security Email",
  "description": "Rate-limit and guardrail alerts",
  "enabled": true,
  "labels": { "email_address": "${ALERT_EMAIL}" }
}
JSON

CHANNEL_NAME=$(gcloud beta monitoring channels create \
  --channel-content-from-file=/tmp/email-channel.json \
  --format="value(name)")
echo "Notification channel: ${CHANNEL_NAME}"

# 3) Alert policy: any blocks in 5 minutes
cat > /tmp/alert-policy.json <<JSON
{
  "displayName": "CRITICAL: Rate-limit blocks > 0 (5m)",
  "combiner": "OR",
  "conditions": [
    {
      "displayName": "Blocks > 0 in 5m",
      "conditionThreshold": {
        "filter": "metric.type = \\"logging.googleapis.com/user/rate_limit_blocks\\"",
        "comparison": "COMPARISON_GT",
        "thresholdValue": 0,
        "duration": "300s",
        "trigger": { "count": 1 }
      }
    }
  ],
  "notificationChannels": ["${CHANNEL_NAME}"],
  "documentation": {
    "content": "Investigate edge 429s (Cloud Armor). See S-1 runbook.",
    "mimeType": "text/markdown"
  }
}
JSON

gcloud alpha monitoring policies create --policy-from-file=/tmp/alert-policy.json
echo "Alert policy created."
```

---

## Budget Alerts (REST via curl)

We’ll use the **Billing Budgets API** with your `gcloud` access token. Create **daily** and **monthly** budgets that notify your Security email channel (above) or default recipients.

**File:** `scripts/setup_budgets.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail

# ====== CONFIG ======
BILLING_ACCOUNT="${BILLING_ACCOUNT:?Set BILLING_ACCOUNT like 000000-000000-000000}"
PROJECT_ID="${PROJECT_ID:-cwechatbot}"
CURRENCY="${CURRENCY:-EUR}"
DAILY_UNITS="${DAILY_UNITS:-50}"     # daily cap
MONTHLY_UNITS="${MONTHLY_UNITS:-500}"# monthly cap
# ====================

ACCESS_TOKEN=$(gcloud auth print-access-token)

# Monthly budget (thresholds at 50% and 90%)
cat > /tmp/monthly-budget.json <<JSON
{
  "displayName": "Monthly Budget",
  "budgetFilter": {
    "projects": ["projects/${PROJECT_ID}"]
  },
  "amount": {
    "specifiedAmount": { "currencyCode": "${CURRENCY}", "units": "${MONTHLY_UNITS}" }
  },
  "thresholdRules": [
    { "thresholdPercent": 0.5 },
    { "thresholdPercent": 0.9 }
  ],
  "allUpdatesRule": {
    "disableDefaultIamRecipients": false
  }
}
JSON

curl -sS -X POST \
  -H "Authorization: Bearer ${ACCESS_TOKEN}" \
  -H "Content-Type: application/json" \
  -d @/tmp/monthly-budget.json \
  "https://billingbudgets.googleapis.com/v1/billingAccounts/${BILLING_ACCOUNT}/budgets" \
  | sed -e 's/^/MONTHLY: /'

# Daily budget (calendarPeriod DAILY; alert at 100%)
cat > /tmp/daily-budget.json <<JSON
{
  "displayName": "Daily Budget",
  "budgetFilter": {
    "projects": ["projects/${PROJECT_ID}"],
    "calendarPeriod": "DAILY"
  },
  "amount": {
    "specifiedAmount": { "currencyCode": "${CURRENCY}", "units": "${DAILY_UNITS}" }
  },
  "thresholdRules": [
    { "thresholdPercent": 1.0 }
  ],
  "allUpdatesRule": {
    "disableDefaultIamRecipients": false
  }
}
JSON

curl -sS -X POST \
  -H "Authorization: Bearer ${ACCESS_TOKEN}" \
  -H "Content-Type: application/json" \
  -d @/tmp/daily-budget.json \
  "https://billingbudgets.googleapis.com/v1/billingAccounts/${BILLING_ACCOUNT}/budgets" \
  | sed -e 's/^/DAILY: /'
```

> Notes:
>
> * You need **Billing Account Viewer** or better on the billing account.
> * To send alerts to a **Monitoring channel**, you can configure Pub/Sub routing + a small notifier, but email to billing admins is often sufficient for a first pass.

---

## Black-box Tests

### 1) Pytest: proves 200 → 429 from the **edge**

**File:** `tests/integration/test_rate_limit.py`

```python
import os, time, requests

BASE_URL = os.environ.get("STAGING_URL")  # e.g., https://staging.example.com/healthz
ASSERT_429_AFTER = int(os.environ.get("TEST_RATE_LIMIT", "10"))

HEADERS = {}
user_id = os.environ.get("TEST_USER_ID")
if user_id:
    HEADERS["X-User-Id"] = user_id

def test_rate_limit_200_then_429():
    assert BASE_URL, "Set STAGING_URL to your public endpoint (a cheap GET)."

    # Warm-up within limit
    for i in range(ASSERT_429_AFTER):
        r = requests.get(BASE_URL, headers=HEADERS, timeout=10)
        assert r.status_code < 500, f"Upstream error on request {i} ({r.status_code})"

    # This one should tip over into 429
    r = requests.get(BASE_URL, headers=HEADERS, timeout=10)
    assert r.status_code == 429, f"Expected 429 after {ASSERT_429_AFTER}, got {r.status_code}"

    # Cooldown to avoid polluting neighbors
    time.sleep(2)
```

**Run:**

```bash
STAGING_URL="https://staging.example.com/healthz" \
TEST_USER_ID="itest-user-1" \
TEST_RATE_LIMIT=10 \
pytest -q tests/integration/test_rate_limit.py
```

### 2) Bash micro-load (no Python)

**File:** `scripts/hit_until_429.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail

URL="${1:?Usage: $0 https://staging.example.com/healthz}"
COUNT="${COUNT:-15}"
USER_ID="${USER_ID:-itest-user-1}"

echo "Hitting $URL up to $COUNT times..."
for i in $(seq 1 "$COUNT"); do
  CODE=$(curl -s -o /dev/null -w "%{http_code}" -H "X-User-Id: ${USER_ID}" "$URL")
  echo "[$i] -> $CODE"
  if [ "$CODE" -eq 429 ]; then
    echo "Got 429 on request $i (as expected)."
    exit 0
  fi
done

echo "Did not receive 429 after $COUNT requests."
exit 1
```

---

## Runbook (Ops)

1. **Symptom:** Users report 429s / UI shows “Too Many Requests”.
2. **Triage:**

   * Logs Explorer filter: `text:("DENY_429") OR jsonPayload.enforcedAction="DENY_429"`.
   * Check **rate_limit_blocks** metric and alert history.
   * Identify key: `X-User-Id` vs IP (look at log fields).
3. **Decision:**

   * If abuse: keep as-is or **increase ban duration** temporarily.
   * If legit traffic spike: temporarily **raise rpm** (and monitor), or add **per-user exception** via gateway (Apigee plan, etc.).
4. **Coordinate:** If rate limits are fine but content is blocked, hand off to **S-2** runbook (Model Armor/Safety).
5. **Post-incident:** Capture user/IP/key, window, reason; tune baseline limits.

---

## Change Management

* Apply in **staging** first; run tests.
* Announce **prod** change window; apply policy; immediately run tests.
* Monitor **rate_limit_blocks** and app latency for 24h; adjust as needed.

---

## Acceptance Validation

* 429s enforced at edge for both **per-IP** and **per-user** (prove with/without `X-User-Id`).
* **Configurable** RPM/interval/ban via script env vars.
* **Budget alerts** exist and fire in a sandbox test (lower thresholds temporarily in a test project).
* **Observability** metric + alert visible in Monitoring; email received.
* Tests (`pytest` and bash) pass in staging and prod smoke.

---

## Dependencies & Notes

* **Identity header** set by IAP/API gateway/JWT middleware (S-9 alignment).
* **WAF rules, TLS/HSTS, request size caps**: configured under **S-9**.
* **Content guardrails** (Model Armor/Safety/DLP): **S-2**.

---

If you want, I can bundle these files into a zip or open a structured PR tree with:

* `docs/stories/S-1-managed-rate-limits.md`
* `scripts/setup_rate_limits.sh`
* `scripts/setup_rate_limit_observability.sh`
* `scripts/setup_budgets.sh`
* `scripts/hit_until_429.sh`
* `tests/integration/test_rate_limit.py`
