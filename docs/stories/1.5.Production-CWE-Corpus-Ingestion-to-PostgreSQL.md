# Story 1.5: Production-CWE-Corpus-Ingestion-to-PostgreSQL

**Status**: Draft

## Story

**As a** production deployment team,
**I want** to ingest the complete MITRE CWE corpus using Gemini embeddings into a production PostgreSQL+pgvector database,
**so that** the CWE ChatBot has access to the full, production-ready knowledge base for effective RAG operations.

## Acceptance Criteria

1. **AC1**: A production PostgreSQL database with pgvector extension is configured in Google Cloud SQL with proper schema and vector indexes for 3072-dimensional embeddings.

2. **AC2**: The complete MITRE CWE corpus (969+ CWEs) is successfully ingested using Gemini embeddings with all required fields extracted and stored.

3. **AC3**: Vector similarity search operations perform within acceptable response times (< 500ms for k=10 results) using appropriate database indexes.

4. **AC4**: Database connections are securely configured with encrypted connections and proper credential management.

5. **AC5**: The ingestion process is documented and can be triggered for production deployment with proper monitoring and logging.

## Security Requirements

1. **Authentication**: Use Google Cloud IAM authentication for database access via Cloud SQL Auth Proxy (no passwords required)
2. **Authorization**: Database access restricted using IAM roles (Cloud SQL Client role) for authorized service accounts only
3. **Input Validation**: All CWE data validated and sanitized before database storage to prevent injection attacks
4. **Data Protection**: IAM-based authentication with encrypted connections, no password storage required
5. **Compliance**: Audit logging of all ingestion operations with timestamps and success/failure status

## Tasks / Subtasks

- [ ] **Task 1: PostgreSQL Vector Store Implementation (AC: 1, 4)**
  - [ ] Create `PostgreSQLVectorStore` class in `apps/cwe_ingestion/postgres_vector_store.py`
  - [ ] Implement database connection using psycopg2 with Cloud SQL Auth Proxy and IAM authentication
  - [ ] Implement vector storage methods compatible with existing pipeline interface
  - [ ] Configure IAM-based authentication (no password storage required)
  - [ ] Security validation: Ensure encrypted connections and IAM role-based access

- [ ] **Task 2: Production Database Setup (AC: 1)**
  - [ ] Create Cloud SQL PostgreSQL instance with pgvector extension
  - [ ] Configure IAM database users for service account authentication
  - [ ] Implement database schema creation from README specifications
  - [ ] Configure vector indexes (IVFFlat) for 3072-dimensional embeddings
  - [ ] Set up IAM roles (Cloud SQL Client) for ingestion service account
  - [ ] Security validation: Verify IAM-based access controls and encryption

- [ ] **Task 3: Full Corpus Ingestion Pipeline (AC: 2)**
  - [ ] Update pipeline configuration to use PostgreSQL vector store for production
  - [ ] Implement full CWE corpus processing (remove target CWE filtering)
  - [ ] Add progress tracking and logging for large-scale ingestion
  - [ ] Implement batch processing optimization for 969+ CWEs
  - [ ] Verify all CWE fields are properly extracted and stored

- [ ] **Task 4: Production Performance Optimization (AC: 3)**
  - [ ] Implement and test vector similarity search performance
  - [ ] Optimize database indexes for query performance (< 500ms target)
  - [ ] Add connection pooling for production database access
  - [ ] Performance testing with full corpus and query benchmarking
  - [ ] Monitor and log ingestion performance metrics

- [ ] **Task 5: Production Environment Configuration (AC: 5)**
  - [ ] Configure service account for Cloud SQL IAM authentication
  - [ ] Set up environment variables for Cloud SQL instance connection (no passwords)
  - [ ] Add production deployment documentation with IAM setup procedures
  - [ ] Create monitoring and alerting for ingestion pipeline health
  - [ ] Security validation: Audit IAM roles and access patterns

- [ ] **Security Requirements Implementation**
  - [ ] Implement authentication controls for database access
  - [ ] Implement authorization controls and access restrictions
  - [ ] Implement input validation for CWE data
  - [ ] Implement data protection with encryption and secure credential storage
  - [ ] Verify compliance requirements with audit logging

## Dev Notes

### Previous Story Insights
**From Story 1.3 Implementation [Source: docs/stories/1.3.CWE-Data-Ingestion-Pipeline.md]:**
- ✅ **Secure Foundation**: Established secure ingestion pipeline with XXE protection using defusedxml
- ✅ **Environment Variable Handling**: Proper API key management patterns established
- ✅ **CLI Interface**: Command-line interface for ingestion operations
- ✅ **Test Coverage**: Comprehensive test suite for ingestion components
- ✅ **ChromaDB Integration**: Local vector database for development and testing

**From Story 1.4 Implementation [Source: docs/stories/1.4.Gemini-Optimized-CWE-Data-Ingestion-Pipeline.md]:**
- ✅ **Gemini Integration**: GeminiEmbedder with 3072-dimensional embeddings
- ✅ **Dual Embedder Support**: Configurable embedder type (local/gemini)
- ✅ **API Key Security**: Secure GEMINI_API_KEY handling with masking
- ✅ **Production Documentation**: Complete README with PostgreSQL architecture
- ✅ **Bug Fixes**: Temporary file handling and XML namespace parsing resolved

### Data Models
**PostgreSQL Schema [Source: apps/cwe_ingestion/README.md#postgresql-schema]:**
```sql
CREATE TABLE cwe_embeddings (
    id VARCHAR(20) PRIMARY KEY,
    cwe_id VARCHAR(10) NOT NULL,
    name TEXT NOT NULL,
    abstraction VARCHAR(20),
    status VARCHAR(20),
    description TEXT,
    extended_description TEXT,
    full_text TEXT NOT NULL,
    embedding vector(3072) NOT NULL,  -- Gemini dimensions
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Vector similarity index
CREATE INDEX cwe_embeddings_embedding_idx
ON cwe_embeddings USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

**Vector Database Schema [Source: docs/architecture/database-schema.md#vector-database-conceptual-schema]:**
- **Index Configuration**: 3072 dimensions for gemini-embedding-001
- **Metric Type**: Cosine similarity for text embeddings
- **Metadata Structure**: cwe_id, name, short_description, full_text, version, last_updated

### API Specifications
**Gemini Embedding API [Source: docs/stories/1.4.Gemini-Optimized-CWE-Data-Ingestion-Pipeline.md]:**
- **Model**: `gemini-embedding-001`
- **Dimensions**: 3072
- **Authentication**: `GEMINI_API_KEY` environment variable
- **Rate Limits**: Standard Google AI API quotas apply
- **Cost**: $0.15 per 1M input tokens

**PostgreSQL Connection [Source: docs/architecture/tech-stack.md]:**
- **Database**: PostgreSQL 14.x on Google Cloud SQL
- **Extension**: pgvector for vector operations
- **Authentication**: IAM-based authentication via Cloud SQL Auth Proxy
- **Environment Variables**: `CLOUD_SQL_CONNECTION_NAME`, `DB_NAME`, `GOOGLE_APPLICATION_CREDENTIALS`

### File Locations
**Current Implementation [Source: docs/architecture/unified-project-structure.md]:**
- **Implementation Base**: `apps/cwe_ingestion/` (established in Stories 1.3/1.4)
- **Key Files**:
  - `apps/cwe_ingestion/pipeline.py` - Main ingestion orchestrator
  - `apps/cwe_ingestion/embedder.py` - Dual embedder support (local/gemini)
  - `apps/cwe_ingestion/vector_store.py` - Currently ChromaDB, needs PostgreSQL adapter
  - `apps/cwe_ingestion/cli.py` - Command interface with --embedder-type option
  - `apps/cwe_ingestion/README.md` - Complete production documentation

**New Files Required**:
- `apps/cwe_ingestion/postgres_vector_store.py` - PostgreSQL+pgvector implementation
- Production environment configuration files

### Technical Constraints
**Technology Stack [Source: docs/architecture/tech-stack.md]:**
- **Database**: PostgreSQL 14.x with pgvector extension
- **Cloud Platform**: Google Cloud Platform with Cloud SQL
- **Vector Dimensions**: 3072 (Gemini embedding model)
- **Python Version**: 3.10+
- **Dependency Management**: Poetry for reproducible environments

**Performance Requirements [Source: AC3]:**
- Vector similarity search: < 500ms for k=10 results
- Index Type: IVFFlat or HNSW for efficient similarity search
- Connection pooling for production database access

### Threat Considerations

**Attack Surfaces**:
- PostgreSQL database connection introduces additional attack surface for production deployment
- Google Cloud SQL Auth Proxy connection security dependencies
- Production credential storage and access patterns
- Network connectivity between ingestion pipeline and Cloud SQL instance

**Threat Scenarios**:
- **Service Account Compromise**: Compromised service account could lead to unauthorized database access
- **Connection Interception**: Unencrypted database connections could expose CWE data in transit
- **SQL Injection**: Malformed CWE data could lead to database injection attacks if not properly sanitized
- **Privilege Escalation**: Overprivileged IAM roles could allow broader access than needed

**Required Security Controls**:
- Encrypted database connections (SSL/TLS) with certificate validation
- IAM-based authentication with least privilege service accounts
- Input validation and sanitization for all CWE data before database operations
- Least privilege IAM roles (Cloud SQL Client role only)
- Connection pooling with secure configuration

**Risk Mitigation**:
- Use Cloud SQL Auth Proxy with IAM authentication for secure, encrypted connections
- Configure service accounts with minimal required IAM roles, no password storage
- Implement comprehensive input validation following existing XXE protection patterns
- Use parameterized queries to prevent SQL injection
- Implement database connection monitoring and alerting

### Implementation Plan
**Detailed Plan Available**: See `docs/plans/1.5.Production-CWE-Corpus-Ingestion-to-PostgreSQL.md` for comprehensive implementation steps, code examples, and verification procedures.

### Testing Standards
**Test Framework [Source: existing Stories 1.3/1.4 patterns]:**
- **Location**: `apps/cwe_ingestion/tests/unit/` and `apps/cwe_ingestion/tests/integration/`
- **Framework**: Pytest with existing test foundation
- **Standards**: TDD methodology - write failing tests first, then implement
- **Patterns**: Arrange-Act-Assert pattern, mock external dependencies for unit tests
- **Database Testing**: Use test database instances for integration tests, mock for unit tests

## Testing

### Unit Tests
- [ ] **Test PostgreSQLVectorStore connection initialization and configuration**
- [ ] **Test vector storage and retrieval operations with 3072-dimensional embeddings**
- [ ] **Test database schema creation and index configuration**
- [ ] **Test error handling for database connection failures**
- [ ] **Test batch processing optimization for large CWE corpus**
- [ ] **Test environment variable configuration and validation**

### Integration Tests
- [ ] **Test complete pipeline from CWE download to PostgreSQL storage**
- [ ] **Test Cloud SQL connection with Auth Proxy integration**
- [ ] **Test full corpus ingestion with Gemini embeddings (subset for CI)**
- [ ] **Test vector similarity search performance with indexed data**
- [ ] **Test database schema migration and upgrade procedures**
- [ ] **Test concurrent access and connection pooling under load**

### Security Verification
- [ ] **Secure Database Connection:** Verify all database connections use SSL/TLS encryption with certificate validation enabled
- [ ] **IAM Authentication:** Confirm database access uses IAM authentication via service accounts, no passwords stored or logged
- [ ] **Input Validation:** Test all CWE data inputs for proper sanitization before database storage to prevent SQL injection
- [ ] **Access Controls:** Verify database access is restricted to authorized service accounts with Cloud SQL Client role only
- [ ] **Audit Logging:** Validate that all ingestion operations are logged with proper timestamps and status information
- [ ] **SQL Injection Prevention:** Test database queries with malformed input to ensure parameterized queries prevent injection
- [ ] **Connection Security:** Test Cloud SQL Auth Proxy with IAM authentication and verify encrypted connection establishment
- [ ] **Privilege Validation:** Confirm service account has minimum required IAM roles for ingestion operations
- [ ] **Google Cloud Security Review:** Security architect must review the implementation against Google Cloud security best practices and Cloud SQL security guidelines

### Manual Verification
- [ ] **Run complete CWE corpus ingestion from CLI and verify successful database storage**
- [ ] **Check Cloud SQL instance for proper schema creation and data population**
- [ ] **Verify vector similarity search performance meets < 500ms requirement**
- [ ] **Test production environment configuration with IAM service account authentication**
- [ ] **Validate monitoring and logging shows successful ingestion completion**
- [ ] **Perform sample queries against full corpus to verify data quality and search accuracy**

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| September 18, 2025 | 1.0 | Initial story creation for production CWE corpus ingestion | Bob (SM) |