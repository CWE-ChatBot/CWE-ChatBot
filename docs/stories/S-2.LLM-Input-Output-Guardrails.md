# Story S-2: Enforce LLM I/O Guardrails with Google Cloud Services

**Status:** Proposed (replacing prior “implement in app” approach)
**Outcome:** Guardrails are enforced by managed Google Cloud services; app code is limited to wiring and policy configuration.
**Note:** Any Infrastructure-as-Code work is deferred to **S-11.Infrastructure-as-CodeTF.md**.


## Story

**As a** Security Engineer,
**I want** Google Cloud–managed protections on all LLM inputs/outputs,
**so that** prompt injection, jailbreaks, sensitive-data leaks, and unsafe content are prevented without bespoke code.

## Acceptance Criteria

1. **Model Armor policies** are applied to every prompt/response on the serving path (Vertex AI / Gemini endpoints) to detect & block prompt injection, jailbreaks, data-loss attempts, malicious URLs, and unsafe content; blocked events return a generic error to the user and are logged. ([Google Cloud][1])
2. **Vertex AI Safety & content filters** are enabled with documented thresholds for harassment, hate, sexual, and dangerous content; thresholds are version-controlled and auditable. ([Google Cloud][2])
3. **Structured output** is enforced via **responseSchema** (JSON) and/or **Function Calling** (OpenAPI schema) so tool args are constrained; non-conforming output is rejected or auto-fixed by the platform. ([Google AI for Developers][3])
4. **Sensitive Data Protection (DLP)** is used to inspect and (where configured) mask/redact sensitive fields in prompts *before* model invocation and in model outputs *before* display/logging. Policy covers at least emails, phone numbers, government IDs, and payment data. ([Google Cloud][4])
5. **Auditability:** Cloud **Audit Logs** for Vertex AI “Data Access” are enabled; Cloud **Logging** captures allow/deny decisions from Model Armor/Safety filters, with a centralized **CRITICAL** severity for blocks and a redacted payload snapshot. ([Google Cloud][5])
6. **Grounding/quality (optional, if used):** When grounding is enabled, it uses **Vertex AI Search** and/or **Google Search grounding** to reduce hallucinations; configuration is documented. ([Google Cloud][6])
7. **Runbooks:** An ops runbook describes how to change thresholds/policies, view/triage blocked events, and roll back safely.

## Security Requirements

1. **Secure LLM Boundary (managed):** All LLM I/O must traverse Model Armor + Safety Filters + (optional) DLP pipelines; direct calls to the model without these controls are prohibited by policy and IaC. ([Google Cloud][1])
2. **Defense in Depth:** Input screening (Model Armor + DLP) and output screening (Safety filters + Model Armor + DLP) are both active; disabling one fails deployment checks. ([Google Cloud][1])

## Tasks / Subtasks

* [ ] **T1: Wire Model Armor on serve path** (AC: 1, 2)

  * [ ] Enable Model Armor for the project/region used by Vertex AI endpoints; apply recommended “Prompt Injection/Jailbreak/Data Loss/URL/Offense” shields. ([Google Cloud][1])
  * [ ] Set failure behavior: **block + generic error**; emit structured log (policy, reason, hash of payload).

* [ ] **T2: Configure Vertex AI Safety filters** (AC: 2)

  * [ ] Set category thresholds per product policy; check in config to repo with environment overlays (dev/stage/prod). ([Google Cloud][2])

* [ ] **T3: Enforce structured output** (AC: 3)

  * [ ] For pure responses, set `responseSchema` to force JSON; for tools, use **Function Calling** with OpenAPI-compatible schemas; enable “forced function calling” where applicable. ([Google AI for Developers][3])

* [ ] **T4: Sensitive-data inspection/redaction** (AC: 4)

  * [ ] Create DLP inspection templates & de-identification (masking/redaction) templates; apply on request path pre-model and on response path pre-UI/log. ([Google Cloud][4])

* [ ] **T5: Observability & Audit** (AC: 5)

  * [ ] Enable **Data Access** audit logs for Vertex AI; route Model Armor/Safety/DLP decisions to Cloud Logging with log-based metrics and alerting (PagerDuty/Email) on **CRITICAL** blocks. ([Google Cloud][5])

* [ ] **T6: Grounding config (optional)** (AC: 6)

  * [ ] If enabled, document Vertex AI Search sources and/or Google Search grounding flags; verify citations/metadata return. ([Google Cloud][6])

* [ ] **T7: IaC & Policy Guard**

  * [ ] Terraform/Blueprints enforce that endpoints are created with Safety/Model-Armor/DLP configs; a policy validator blocks drift.

* [ ] **T8: Runbooks & SOPs** (AC: 7)

  * [ ] Create operator SOP for threshold tuning, incident response, and rollback.

## Dev Notes

* **Why this change:** Google Cloud **Model Armor** provides managed shields for prompt injection/jailbreak/data-loss and unsafe content across prompts *and* responses, reducing bespoke code and keeping protections current. ([Google Cloud][1])
* **Structured output:** Prefer **responseSchema** (strict JSON) or **Function Calling** with schemas to reduce free-form text and hallucinated tool calls. ([Google AI for Developers][3])
* **DLP:** Use inspection + masking templates to keep secrets/PII out of prompts, responses, and logs. ([Google Cloud][4])
* **Bot abuse:** Consider **reCAPTCHA Enterprise** at chat entry points to reduce automated attacks (optional). ([Google Cloud][7])

## Testing

### Automated

* [ ] **Shield E2E tests:** Replay a corpus of known jailbreak/injection strings; assert **Model Armor blocked** and user received a generic error; verify CRITICAL log present. ([Google Cloud][1])
* [ ] **Safety thresholds:** Generate test content across categories; assert pass/fail matches configured thresholds. ([Google Cloud][2])
* [ ] **Schema adherence:** Send prompts that try to elicit non-JSON or wrong schema; assert platform returns structured output or fails closed. ([Google AI for Developers][3])
* [ ] **DLP redaction:** Seed PII/secret tokens in prompts/responses; assert masked/redacted before model/UI/logs. ([Google Cloud][4])
* [ ] **Audit:** Validate Vertex AI **Data Access** logs present for sampled calls. ([Google Cloud][5])

### Manual

* [ ] In UI, attempt prompt injection / system-prompt extraction; verify block + CRITICAL log with reason code. ([Google Cloud][1])
* [ ] Toggle thresholds in non-prod and confirm effect via test prompts. ([Google Cloud][2])

## Change Log

| Date          | Version | Description                                      | Author    |
| ------------- | ------- | ------------------------------------------------ | --------- |
| Oct 6, 2025   | 2.0     | Migrated to Google-managed guardrails & logging. | You       |
| July 30, 2025 | 1.0     | Initial story creation from report.              | John (PM) |
