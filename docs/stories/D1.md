# Debug Issue D1: CSP Blocking Chainlit External CSS

**Date**: 2025-10-10
**Status**: ‚úÖ RESOLVED
**Related**: Story S-12 (CSP Implementation)

## Problem Observed

Browser console (Chrome DevTools) showed CSS resources blocked by Content Security Policy:

```
(blocked:csp)
Request URL: https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap
Referrer Policy: no-referrer

(blocked:csp)
Request URL: https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css
Referrer Policy: no-referrer
```

**Symptoms:**
- Chainlit UI rendering without proper fonts (Inter font family missing)
- Math rendering (KaTeX) CSS not loading
- Visual appearance degraded

## Root Cause Analysis

The CSP implemented in Story S-12 had overly restrictive `style-src` and `font-src` directives:

**Original CSP (apps/chatbot/src/security/middleware.py):**
```python
"style-src 'self' 'unsafe-inline'; "
"font-src 'self' data:; "
```

**Issue:** Only allowed CSS from same origin + inline styles. Blocked external CSS from:
- `fonts.googleapis.com` - Google Fonts (Inter font family used by Chainlit)
- `cdn.jsdelivr.net` - KaTeX CSS for math rendering
- `fonts.gstatic.com` - Google Fonts static assets

## Solution Implemented

Updated CSP to allow trusted external CSS/font sources:

**Fixed CSP:**
```python
"style-src 'self' 'unsafe-inline' https://fonts.googleapis.com https://cdn.jsdelivr.net; "
"font-src 'self' data: https://fonts.gstatic.com; "
```

**File Changed:** `apps/chatbot/src/security/middleware.py`
**Commit:** `575adc9` - Fix CSP to allow Chainlit external CSS and fonts

## Security Analysis

‚úÖ **Safe to allow** - All sources are trusted:
- **fonts.googleapis.com** - Google's official font service (HTTPS-only)
- **cdn.jsdelivr.net** - Popular open-source CDN with automated security scanning
- **fonts.gstatic.com** - Google's font asset delivery (HTTPS-only)

‚úÖ **No new attack surface:**
- Only CSS and font files allowed (no scripts)
- HTTPS-only sources (no downgrade attacks)
- Required for Chainlit UI to function properly
- Standard practice for modern web applications

‚úÖ **Defense-in-depth maintained:**
- Still blocking inline scripts (`script-src` unchanged)
- Still blocking unsafe eval in strict mode
- WebSocket origin pinning unchanged
- Other CSP directives remain strict

## Testing

### Local Testing
```bash
poetry run chainlit run apps/chatbot/main.py
```

**Verification steps:**
1. Open browser DevTools console
2. Check Network tab for CSS requests
3. Verify no `(blocked:csp)` errors for fonts.googleapis.com or cdn.jsdelivr.net
4. Verify UI renders with proper Inter font
5. Test math rendering (if KaTeX is used)

### Production Testing
After deployment:
```bash
# Deploy
gcloud builds submit --config=apps/chatbot/cloudbuild.yaml

# Verify
curl -I https://cwe.crashedmind.com/ | grep -i "content-security-policy"
```

**Expected CSP header:**
```
content-security-policy: default-src 'self'; script-src 'self' 'unsafe-eval'; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com https://cdn.jsdelivr.net; img-src 'self' data: https:; font-src 'self' data: https://fonts.gstatic.com; connect-src 'self' https://cwe.crashedmind.com wss://cwe.crashedmind.com; frame-ancestors 'none'; base-uri 'self'; object-src 'none'; form-action 'self'
```

## Observations

1. **CSP Evolution**: S-12 initially implemented strict CSP without accounting for Chainlit's external dependencies
2. **Compatibility vs Security**: Need to balance security strictness with framework requirements
3. **CDN Trust**: Modern web apps commonly trust well-established CDNs (Google, jsDelivr)
4. **HTTPS Requirement**: All external sources must use HTTPS to maintain security

## Resolution Status

‚úÖ **Code committed**: Commit `575adc9`
‚è≥ **Deployment pending**: Needs production deployment
‚è≥ **Verification pending**: Browser console test after deployment

## Related Issues

**Issue #2 (below):** Duplicate welcome messages observed
**Issue #3 (below):** Chainlit response truncation

---

# Debug Issue D2: Duplicate Welcome Messages

**Date**: 2025-10-10
**Status**: üîç INVESTIGATING
**Related**: OAuth/Session Management

## Problem Observed

Welcome message appears multiple times in the chat interface:

```
"Welcome back, wasp bee! üõ°Ô∏è
Authenticated via Google
üîê Your session is secure and your persona preferences will be saved.
I'm here to help you with Common Weakness Enumeration (CWE) information. Let me guide you through getting started:"
```

**Context from browser request:**
```
Request URL: https://cwe.crashedmind.com/project/file/98042020-f1d3-4d54-913c-4aabc9aed2ff?session_id=5492a85e-6b67-4354-85b9-1c50fa969387
Request Method: GET
Status Code: 200 OK
Remote Address: 34.49.0.7:443 (Load Balancer)

Authentication: Google OAuth
User: wasp bee (crashedmind@gmail.com)
Session ID: 5492a85e-6b67-4354-85b9-1c50fa969387
```

## Potential Root Causes

1. **Multiple session initialization events** - Chainlit may be triggering `@cl.on_chat_start` multiple times
2. **Message caching/replay** - Session restore replaying welcome message
3. **WebSocket reconnection** - Connection drops causing re-initialization
4. **Race condition** - Multiple async handlers sending welcome concurrently

## Investigation Steps

- [ ] Check Chainlit session logs for multiple `on_chat_start` events
- [ ] Review session restoration logic in `apps/chatbot/main.py`
- [ ] Check for duplicate message deduplication logic
- [ ] Monitor WebSocket connection stability
- [ ] Review Cloud Logging for session initialization patterns

## Observations

- Session ID is consistent: `5492a85e-6b67-4354-85b9-1c50fa969387`
- User authentication is working correctly (Google OAuth)
- No errors visible in browser console (besides CSS blocking - Issue D1)

---

# Debug Issue D3: Chainlit Response Truncation

**Date**: 2025-10-10
**Status**: üîç INVESTIGATING (Regression)
**Related**: Story S-9 (Previous fix attempted)

## Problem Observed

Chainlit responses are prematurely truncated, cutting off LLM output mid-sentence.

**Important Notes:**
- **NOT related to LLM response length** - Verified in logs
- **Debug logging added** - Per git history from yesterday
- **Suspected regression** - Thought this was fixed previously

## Previous Fix Attempts

From git history (yesterday):
- Debug logging was added
- Issue was believed to be resolved
- Root cause identified and fixed (need to check commits)

## Current Status

Issue has recurred, suggesting:
1. **Incomplete fix** - Original fix didn't address all cases
2. **New regression** - Recent code changes reintroduced the problem
3. **Environment-specific** - Works in some scenarios but not others

## Investigation Steps

- [ ] Review git commits from yesterday for truncation fix
- [ ] Check Cloud Logging for debug output added yesterday
- [ ] Compare LLM response length in logs vs UI display length
- [ ] Review Chainlit streaming logic in `apps/chatbot/main.py`
- [ ] Check for buffer size limits or timeout issues
- [ ] Test with different LLM providers (Gemini vs Claude)

## Related Code Areas

Files to investigate:
- `apps/chatbot/src/llm_provider.py` - LLM response handling
- `apps/chatbot/main.py` - Chainlit streaming logic
- `apps/chatbot/src/response_generator.py` - Response generation
- `apps/chatbot/src/processing/pipeline.py` - Processing pipeline

## Observations

- User can see truncation happening in real-time
- Full response exists in backend logs (per notes)
- Issue appears to be in UI streaming/display layer




I have also observed that the welcome text appears more than once in a chat:
"Welcome back, wasp bee! üõ°Ô∏è
Authenticated via Google
üîê Your session is secure and your persona preferences will be saved.
I'm here to help you with Common Weakness Enumeration (CWE) information. Let me guide you through getting started:" 


Request URL
https://cwe.crashedmind.com/project/file/98042020-f1d3-4d54-913c-4aabc9aed2ff?session_id=5492a85e-6b67-4354-85b9-1c50fa969387&
Request Method
GET
Status Code
200 OK
Remote Address
34.49.0.7:443
Referrer Policy
no-referrer
:authority
cwe.crashedmind.com
:method
GET
:path
/project/file/98042020-f1d3-4d54-913c-4aabc9aed2ff?session_id=5492a85e-6b67-4354-85b9-1c50fa969387&
:scheme
https
accept
*/*
accept-encoding
gzip, deflate, br, zstd
accept-language
en-US,en;q=0.9
cookie
access_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZGVudGlmaWVyIjoiZ29vZ2xlOmNyYXNoZWRtaW5kQGdtYWlsLmNvbSIsImRpc3BsYXlfbmFtZSI6bnVsbCwibWV0YWRhdGEiOnsicHJvdmlkZXIiOiJnb29nbGUiLCJlbWFpbCI6ImNyYXNoZWRtaW5kQGdtYWlsLmNvbSIsIm5hbWUiOiJ3YXNwIGJlZSIsImF2YXRhcl91cmwiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NMN25Oa2piTHNTX2xtMkVHcUNHRFNTT1lCNVNsN2UzR3RVdktELS1LVVo5RmdYeHc9czk2LWMiLCJyYXdfZGF0YSI6eyJpZCI6IjEwNzIzMzM3MTQyNTI5OTQxMTUyMCIsImVtYWlsIjoiY3Jhc2hlZG1pbmRAZ21haWwuY29tIiwidmVyaWZpZWRfZW1haWwiOnRydWUsIm5hbWUiOiJ3YXNwIGJlZSIsImdpdmVuX25hbWUiOiJ3YXNwIiwiZmFtaWx5X25hbWUiOiJiZWUiLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jTDduTmtqYkxzU19sbTJFR3FDR0RTU09ZQjVTbDdlM0d0VXZLRC0tS1VaOUZnWHh3PXM5Ni1jIn19LCJleHAiOjE3NjEzMTE2MzksImlhdCI6MTc2MDAxNTYzOX0.iKSZojDhQTgMmY9JkhKkmhCoTV5iOoTLI0aGE9rSjKA; X-Chainlit-Session-id=5492a85e-6b67-4354-85b9-1c50fa969387
dnt
1
priority
u=1, i
sec-ch-ua
"Not)A;Brand";v="8", "Chromium";v="138", "Google Chrome";v="138"
sec-ch-ua-mobile
?0
sec-ch-ua-platform
"Linux"
sec-fetch-dest
empty
sec-fetch-mode
cors
sec-fetch-site
same-origin
user-agent
Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36






I am seeing behavior where the chainlit response is prematurely truncated. we saw this before and thought we fixed it per git history yesterday.. it is not related to llm response length and we did add debug in logs. 
I can also see that (blocked:csp)	