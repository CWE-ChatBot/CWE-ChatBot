# Story 1.3: Initial CWE Data Ingestion Pipeline

**Status**: Ready for Review

## Story

**As a** data engineer,
**I want** an automated pipeline to ingest a small, curated subset of CWE data (e.g., 5-10 specific CWEs from MITRE's XML/JSON) into a vector database,
**so that** the chatbot can begin to retrieve basic information.

## Acceptance Criteria

1.  A Python script or service is developed to download the latest public CWE XML/JSON data from the MITRE website.
2.  The script can parse and extract the following specific CWE fields for a small, pre-defined subset of CWEs (e.g., CWE-79, CWE-89, CWE-20):
    - **ID**: CWE identifier (e.g., "79")
    - **Name**: Name of the weakness (e.g., "Cross-site Scripting")
    - **Abstraction**: Abstraction level (Base, Variant, Class, etc.)
    - **Status**: Current status (Draft, Incomplete, Stable, etc.)
    - **Description**: Main description text
    - **ExtendedDescription**: Extended details (if available)
    - **AlternateTerms**: Alternative terminology with descriptions
    - **ObservedExamples**: Real-world examples with references
    - **RelatedWeaknesses**: Relationships to other CWEs with nature and IDs
3.  Embeddings are generated for this subset of CWEs using a selected embedding model (e.g., a local sentence transformer or an external API).
4.  The generated embeddings and corresponding CWE metadata (ID, Name, Abstraction, Status, and all extracted fields) are successfully stored in the chosen vector database (e.g., Pinecone, Weaviate, or a simple in-memory vector store for MVP validation).
5.  The ingestion process is repeatable and can be manually triggered via a command-line interface or simple function call, and produces a verifiable local output (e.g., confirmation log, sample data file, or queryable local vector store).

## Security Requirements

1.  **Secure Data Handling:** The XML/JSON parser used MUST be configured to prevent parsing-based attacks, such as XML External Entity (XXE) injection, by disabling DTDs and external entity resolution.
2.  **API Key Security:** If an external service is used for generating embeddings, the API key MUST be loaded from environment variables or a secure secrets manager. It MUST NOT be hardcoded in the source code.
3.  **Data Integrity:** The download script SHOULD validate the integrity of the downloaded CWE data if checksums or signatures are provided by the source.

## Tasks / Subtasks

-   [x] **Task 1: Develop Data Download Module** (AC: 1, Security: 3)
    -   [x] Write a Python function to download the CWE data file from the official MITRE URL.
    -   [x] Implement error handling for network issues or file not found.
-   [x] **Task 2: Implement Secure Parser** (AC: 2, Security: 1)
    -   [x] Choose a Python library for parsing (e.g., `defusedxml` for secure XML parsing).
    -   [x] Configure the parser securely to disable DTD processing.
    -   [x] Write functions to extract the specific CWE fields (ID, Name, Abstraction, Status, Description, ExtendedDescription, AlternateTerms, ObservedExamples, RelatedWeaknesses) for a hardcoded list of 5-10 CWEs.
-   [x] **Task 3: Integrate Embedding Model** (AC: 3, Security: 2)
    -   [x] Select and integrate an embedding model (local Sentence Transformer model with fallback to mock embedder for testing).
    -   [x] Write a function that takes the extracted text and generates vector embeddings.
    -   [x] Ensure no API keys are required for local model (security: no external dependencies).
-   [x] **Task 4: Implement Vector Database Storage** (AC: 4)
    -   [x] Set up a local vector database instance (ChromaDB) for initial development.
    -   [x] Write a function to connect to the database and store the CWE metadata and its corresponding embedding.
-   [x] **Task 5: Create CLI Trigger** (AC: 5)
    -   [x] Use Click library to create a comprehensive command-line interface.
    -   [x] Create main pipeline script that orchestrates the download, parse, embed, and store steps.
    -   [x] Add logging to show progress and confirm successful ingestion.

## Dev Notes

* **RAG Foundation:** This story is the first step in building our Retrieval-Augmented Generation (RAG) system. The quality of the data parsing and embedding will directly impact the chatbot's accuracy.
* **Data Source:** The official CWE data can be found at the [MITRE CWE website](https://cwe.mitre.org/data/downloads.html). We should target the comprehensive XML or JSON formats.
* **Embedding Model Choice:** For the MVP and to align with the self-hosting requirement (`FR19`), using a local open-source model from a library like `sentence-transformers` is highly recommended. This avoids sending potentially sensitive query data to external APIs.
* **Vector Database Choice:** To simplify local development, we can start with an in-memory or file-based vector store like **FAISS** or **ChromaDB**. The architecture should allow for swapping this with a managed cloud service later.

## Testing

### Unit Tests

-   [ ] Write a test for the parser to ensure it correctly extracts data from a sample XML/JSON snippet.
-   [ ] Write a test for the embedding function to confirm it produces vectors of the expected dimension.

### Integration Tests

-   [ ] Write an integration test for the entire pipeline that uses a small, local sample of the CWE data file, runs the ingestion process, and verifies that the data is correctly stored in a temporary local vector database.

### Security Verification

-   [ ] **Code Review:** Manually review the source code to confirm that no API keys are hardcoded.
-   [ ] **Parser Configuration:** Verify that the XML/JSON parsing library is explicitly configured to prevent XXE and other parsing-related vulnerabilities.

### Manual Verification

-   [ ] Run the ingestion script from the command line.
-   [ ] Check the script's log output for success messages.
-   [ ] Write a separate, simple query script to connect to the local vector database and retrieve one of the ingested CWEs to confirm it was stored correctly.

## Dev Agent Record

### Agent Model Used
- **Agent**: James - Full Stack Developer ðŸ’»
- **Model**: Claude Sonnet 4 (claude-sonnet-4-20250514)
- **Implementation Branch**: feature/story-1.3-cwe-data-ingestion-pipeline

### Debug Log References
- Implementation follows TDD methodology per CLAUDE.md
- Security-first development using python-common-vulns.md and python-secure-coding.md guidelines

### Completion Notes List
- [x] Phase 1: TDD Foundation and Data Analysis
- [x] Phase 2: Secure XML Parsing and Data Extraction  
- [x] Phase 3: Local Embedding Model Integration
- [x] Phase 4: Vector Database Integration
- [x] Phase 5: CLI Interface Implementation
- [x] Phase 6: Integration Testing and Validation

### File List
- `pyproject.toml` - Updated with required dependencies (requests, lxml, defusedxml, click, numpy, chromadb)
- `apps/cwe_ingestion/__init__.py` - Module initialization
- `apps/cwe_ingestion/downloader.py` - Secure CWE data downloader with ZIP extraction and network error handling
- `apps/cwe_ingestion/parser.py` - Secure XML parser with XXE protection using defusedxml, extracts all required CWE fields
- `apps/cwe_ingestion/embedder.py` - Local embedding model using sentence-transformers (with mock fallback for testing)
- `apps/cwe_ingestion/vector_store.py` - ChromaDB-based vector database storage with batch operations and querying
- `apps/cwe_ingestion/pipeline.py` - Main pipeline orchestrator combining all components
- `apps/cwe_ingestion/cli.py` - Click-based CLI with ingest, status, query, and reset commands
- `apps/cwe_ingestion/__main__.py` - Module entry point for CLI execution
- `apps/cwe_ingestion/tests/unit/test_downloader.py` - TDD tests for downloader (7 tests)
- `apps/cwe_ingestion/tests/unit/test_parser.py` - TDD tests for parser (6 tests)
- `apps/cwe_ingestion/tests/unit/test_embedder.py` - TDD tests for embedder (8 tests)
- `apps/cwe_ingestion/tests/unit/test_vector_store.py` - TDD tests for vector store (9 tests)
- `apps/cwe_ingestion/tests/integration/test_pipeline.py` - Integration tests for complete pipeline (3 tests)
- Test structure created: `tests/unit/`, `tests/integration/`, `tests/data/` - Total: 33 passing tests

## Change Log

| Date          | Version | Description                   | Author      |
|---------------|---------|-------------------------------|-------------|
| July 30, 2025 | 1.0     | Initial story creation from PRD | John (PM)   |
| August 22, 2025 | 1.1   | Implementation started with TDD approach | James (Dev) |